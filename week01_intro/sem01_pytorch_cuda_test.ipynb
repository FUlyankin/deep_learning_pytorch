{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PzefYvEWqlJu",
    "outputId": "2d7fbc33-a6fe-4b0d-c592-86c18d2516c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb  4 23:02:57 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   64C    P0    30W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N-Fs77ebqr77",
    "outputId": "17496661-a282-4873-a931-2f7802914088"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available() # выясняем есть ли на машине GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujBOhRKoq3Td",
    "outputId": "ec59943f-80f4-4842-c39b-dae6a76607c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRXNwnHEt0hr"
   },
   "outputs": [],
   "source": [
    "# чтобы отправить вычисления на девайс, \n",
    "# надо создать переменную с ним \n",
    "# число - номер видокарты в компе\n",
    "torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4SoASfct2C4"
   },
   "outputs": [],
   "source": [
    "# такой девайс поможет вернуть вычисления на cpu\n",
    "torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3W9rW05At2FN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GEnHi6P0r0Up",
    "outputId": "bb288dfd-403d-41c1-8824-f70756bf3e9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fPju3Mt2r0XY"
   },
   "outputs": [],
   "source": [
    "# на чипах M1 или M2 тоже можно считать \n",
    "# CUDA сделала поддержку, но я пока не тестил\n",
    "# должно работать хуже полноценной видеокарты но лучше CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0EUwcRmCr0Zm",
    "outputId": "9c876511-58ea-4736-b3de-429cbc66b9a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4940,  1.2682, -1.0555, -0.3774,  0.2309,  0.0751,  0.5501,  0.1471,\n",
       "         -0.6900,  0.3678],\n",
       "        [ 1.2831, -1.1831,  0.5866,  0.5913,  0.5013, -1.2075,  1.6582,  0.2835,\n",
       "         -0.5538, -1.7885],\n",
       "        [ 1.2968, -0.6125,  1.4125,  0.7875, -0.9539,  0.2162, -0.5699,  1.7864,\n",
       "         -0.3212, -0.6004],\n",
       "        [-0.1368,  0.3665,  0.5276,  0.3405, -0.8513,  1.4315,  0.8328, -1.2415,\n",
       "         -0.3661, -0.9161],\n",
       "        [ 1.1563, -0.0644, -1.1057, -0.9068, -1.1521,  0.8087,  0.5202, -0.9158,\n",
       "          0.1796,  0.0395],\n",
       "        [ 1.4475, -0.7495, -1.8361, -2.3526,  0.8406, -1.0360,  0.9676, -0.8947,\n",
       "         -1.6046, -1.7287],\n",
       "        [ 1.1179, -0.7721, -0.0830, -0.3833,  1.3195,  1.6918,  2.0732, -0.3755,\n",
       "         -0.3628, -0.8152],\n",
       "        [-0.4569,  0.7572, -1.5697,  0.4656,  0.9502,  0.9881, -0.6074, -0.2223,\n",
       "         -0.5957,  0.6357],\n",
       "        [-1.1210,  0.8653, -0.6431, -1.2508,  1.3576, -1.1747, -0.8135,  0.6152,\n",
       "         -0.4770,  1.0068],\n",
       "        [ 0.1855, -0.4672, -0.6841,  0.4059, -0.7111,  0.3827, -0.0838, -0.2284,\n",
       "          0.6335, -0.7059]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10, 10).to(device)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amQgFdSvryAX",
    "outputId": "aa5a4f73-0cda-4c4c-84d3-0dad68dc8b45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELgmM1pisnEz",
    "outputId": "7a69bba5-275e-41b6-951d-d67bc1cdefba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2305,  1.7533, -0.7878,  1.2625,  0.1171, -0.7931, -0.8220,  1.5732,\n",
       "         -1.0936,  1.5053],\n",
       "        [ 1.7312,  1.0739,  0.2143, -1.1676,  1.2849,  0.1820, -0.9924,  1.2137,\n",
       "         -0.7039, -0.2748],\n",
       "        [ 0.4329,  0.9440, -0.4459,  1.5553,  0.9329,  0.6878,  0.0446, -0.0293,\n",
       "         -0.7106,  0.5674],\n",
       "        [ 1.6844,  1.3877, -0.3441,  1.0064, -1.6527, -0.2623,  0.2892, -0.7749,\n",
       "          0.8195,  0.9864],\n",
       "        [-0.8415,  0.0537,  1.2344, -0.5327,  0.9992, -0.3230, -1.6167,  0.0243,\n",
       "         -2.1348,  0.1886],\n",
       "        [ 1.0107,  0.5081, -1.4460, -1.9167, -0.2820,  0.6500,  0.0458,  0.2480,\n",
       "          0.8121,  0.0285],\n",
       "        [-0.3316,  0.9338, -0.6264,  0.5101, -0.4083,  0.7145, -1.3306,  0.8077,\n",
       "         -1.3127,  1.8818],\n",
       "        [-1.9281,  0.1223,  0.1739,  1.3887, -0.9529, -0.3363,  0.7615, -0.8214,\n",
       "         -0.9968, -0.6844],\n",
       "        [ 0.3799, -0.2678, -0.3567, -0.3760,  0.2535,  0.4894,  0.0494, -0.7052,\n",
       "         -1.7848, -0.6254],\n",
       "        [ 0.1549,  0.0179,  1.7056,  0.1098, -1.3213,  0.2770, -0.9291,  1.0514,\n",
       "         -0.3482, -0.5006]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10, 10, device=device)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-kfV8cNs3J4",
    "outputId": "f76c6de4-fcfc-4ef9-e398-c1e14bea3d98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2305,  1.7533, -0.7878,  1.2625,  0.1171, -0.7931, -0.8220,  1.5732,\n",
       "         -1.0936,  1.5053],\n",
       "        [ 1.7312,  1.0739,  0.2143, -1.1676,  1.2849,  0.1820, -0.9924,  1.2137,\n",
       "         -0.7039, -0.2748],\n",
       "        [ 0.4329,  0.9440, -0.4459,  1.5553,  0.9329,  0.6878,  0.0446, -0.0293,\n",
       "         -0.7106,  0.5674],\n",
       "        [ 1.6844,  1.3877, -0.3441,  1.0064, -1.6527, -0.2623,  0.2892, -0.7749,\n",
       "          0.8195,  0.9864],\n",
       "        [-0.8415,  0.0537,  1.2344, -0.5327,  0.9992, -0.3230, -1.6167,  0.0243,\n",
       "         -2.1348,  0.1886],\n",
       "        [ 1.0107,  0.5081, -1.4460, -1.9167, -0.2820,  0.6500,  0.0458,  0.2480,\n",
       "          0.8121,  0.0285],\n",
       "        [-0.3316,  0.9338, -0.6264,  0.5101, -0.4083,  0.7145, -1.3306,  0.8077,\n",
       "         -1.3127,  1.8818],\n",
       "        [-1.9281,  0.1223,  0.1739,  1.3887, -0.9529, -0.3363,  0.7615, -0.8214,\n",
       "         -0.9968, -0.6844],\n",
       "        [ 0.3799, -0.2678, -0.3567, -0.3760,  0.2535,  0.4894,  0.0494, -0.7052,\n",
       "         -1.7848, -0.6254],\n",
       "        [ 0.1549,  0.0179,  1.7056,  0.1098, -1.3213,  0.2770, -0.9291,  1.0514,\n",
       "         -0.3482, -0.5006]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.cpu() # вернуть назад"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTZylKt_s6-x"
   },
   "outputs": [],
   "source": [
    "# Какая философия у работы с CUDA \n",
    "#\n",
    "# картинки - надо предобработать (обычно на CPU)\n",
    "# сформированный батчи передают на CUDA\n",
    "# сама нейронка и поиск градиентов живут на GPU\n",
    "#\n",
    "# на GPU делаются все сложные операции \n",
    "# вся подготовка данных (логирование, метрики)\n",
    "# должны происходить на CPU чтобы GPU не мешать \n",
    "#\n",
    "# позже научимся смотреть на всякие продвинутые логгеры\n",
    "# чтобы понимать как загружена CPU а как GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "eIJFEOSns7BG"
   },
   "outputs": [],
   "source": [
    "a = torch.rand([10**4,10**4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "eDCwYj-zs7Dl"
   },
   "outputs": [],
   "source": [
    "a_python = a.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSY5tP3ruedJ",
    "outputId": "2b41326d-35d8-4d30-fd37-4805765e83ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.2 s, sys: 1.01 s, total: 11.2 s\n",
      "Wall time: 11.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50003634.091688156"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sum([a_python[i][j] for i in range(10**4) for j in range(10**4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1QFOzBVNueft"
   },
   "outputs": [],
   "source": [
    "a_numpy = a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWwyllTwu1aQ",
    "outputId": "6fb2ce1a-d1cb-4ea6-ddb2-067baa20d59d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.3 ms ± 989 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a_numpy.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cWtbVbXJu1c-",
    "outputId": "9363fd49-b572-4f3d-df80-b4d347af4398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.2 ms ± 316 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "AI6-e8Y-vahS"
   },
   "outputs": [],
   "source": [
    "a_gpu = a.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O1T6KRqmvNtH",
    "outputId": "a1093a2d-438a-4afa-8c18-4fced6dddab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.45 ms ± 81.7 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a_gpu.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAmC-c63vNv-"
   },
   "outputs": [],
   "source": [
    "# На малых размерах матрицы ускорения не будет. Нечего паралелить и мы будем убивать на отправку на GPU лишнее время. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "mD6tv6xevN06"
   },
   "outputs": [],
   "source": [
    "x = torch.rand(5, 5, requires_grad=True)\n",
    "y = torch.rand(5, 5, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "iKbfIqIHu1fN"
   },
   "outputs": [],
   "source": [
    "l = (x * y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Qp4lz2U8s5-J"
   },
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvuT27-Ft8qt",
    "outputId": "0701709a-d8af-4850-db86-0357367b93be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2651, 0.3254, 0.5333, 0.5041, 0.6418],\n",
       "        [0.5235, 0.6928, 0.1576, 0.2332, 0.9100],\n",
       "        [0.4154, 0.7636, 0.5327, 0.7320, 0.9756],\n",
       "        [0.2552, 0.2882, 0.9797, 0.0821, 0.6455],\n",
       "        [0.8962, 0.6800, 0.3154, 0.7787, 0.6608]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "kfSU8hAjt8tT"
   },
   "outputs": [],
   "source": [
    "y.grad # нет градиента - логично :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "id": "PSSQUJ6-t_sW",
    "outputId": "631cd695-621e-4a77-b4ed-e11d84af166e"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1a78c01b16a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# градиенты тащиться не будут,  \n",
    "# вычислительного графа у нас не будет \n",
    "with torch.no_grad():\n",
    "    l = (x * y).sum()\n",
    "    l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "eTP9C5eAt_0B"
   },
   "outputs": [],
   "source": [
    "# более жесткая оптимизация вычислений\n",
    "# в новых версиях торча оптимизирует\n",
    "# ещё какие-то штуки дополнительно \n",
    "# в отличие от no_grad\n",
    "# в каких-то сложных случаях \n",
    "# утверждается что она работает быстрее\n",
    "\n",
    "with torch.inference_mode():\n",
    "    l = (x * y).sum()\n",
    "    # l.backward()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
