{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://camo.githubusercontent.com/1faf678af2925dc98a2fb877b80461f1c992b9e7e229412e5d6b729c49246ffa/68747470733a2f2f7079746f7263682e6f72672f7475746f7269616c732f5f7374617469632f7079746f7263682d6c6f676f2d6461726b2e737667\" height=\"400\" width=\"800\"> \n",
    "\n",
    "# Семинар 1: введение в PyTorch\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фрэймворком для обучения нейросеток на нашем курсе будет PyTorch. Раньше это был Tensorflow. [В прошлом запуске курса](https://github.com/FUlyankin/deep_learning_tf) можно найти много тетрадок с кодом на второй версии библиотеки. \n",
    "\n",
    "В этом году я окончательно решил перевести весь курс на PyTorch. Кажется, что [Google признал его победу](https://t.me/gonzo_ML/1026) и переходит на новую библиотеку, JAX. Если кому-то интересно, он может подробнее почитать про [раличия между Tensorflow и Pytorch.](https://towardsdatascience.com/pytorch-vs-tensorflow-spotting-the-difference-25c75777377b)\n",
    "\n",
    "Ну а мы помянем Tensorflof, нажмём дружно F и больше не будем про него вспоминать в этом курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Устанавливаем библиотеку\n",
    "\n",
    "```\n",
    "pip install torch torchvision\n",
    "```\n",
    "\n",
    "Дополнительно с торчом выходят `torchvision` и `torchaudio`. В них куча всяких методов дял работы с изображениями и звуком. Обе эти библиотеки тоже можно поставить виесте с торчом. Первая из них уже сегодня нам понадобится. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Тензоры и базовые операции над ними\n",
    "\n",
    "Основной объект в PyTorch - это **тензор.** Или многомерный массив чисел. Чтобы не нужно было учить кучу новых команд, PyTorch косплеит numpy. \n",
    "\n",
    "```\n",
    "    np.zeros -> torch.zeros\n",
    "    np.sin -> torch.sin\n",
    "    np.cumsum -> torch.cumsum\n",
    "    \n",
    "    x.reshape([1,2,8]) -> x.view(1,2,8)\n",
    "    x.sum(axis=-1) -> x.sum(dim=-1)\n",
    "    x.astype('int64') -> x.type(torch.LongTensor)\n",
    "```\n",
    "\n",
    "Правда говоря, не совсем косплеит. Но чаще всего оказывается довольно близок. Для помощи вам есть [таблица](https://github.com/torch/torch7/wiki/Torch-for-Numpy-users), которая поможет вам найти аналог операции в numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# как в нумпае можно объявить вектор\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно задать тензор из нулей\n",
    "torch.zeros([3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# или из единиц, но уже более сложной размерности\n",
    "torch.ones([3, 4, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно сгенерировать тензор из стандартного нормального распределения\n",
    "torch.randn([2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty(5, 3) # пустой тензор\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тензор с нулями и указанием типов чисел\n",
    "x = torch.zeros(5, 3, dtype=torch.double) \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # используем уже созданный тензор для создания тензора из единичек\n",
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем матрицу с размерами как у x\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.double() # можно поменяить тип данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# как думаете, почему не пишет dtype? \n",
    "x.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все срезы, операции, размерности работают как в numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(5, 3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x + y) # операция сложение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.add(x, y) # очередная операция сложения\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.add(x, y, out=z) # и наконец последний вид\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x * y) # поэлементное умножение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x @ y.t()) # матричное умножение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# и опять матричное умножение\n",
    "print(x.mm(y.t()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавили измерение в начало, аналог броадкастинга \n",
    "print(x.unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убрали измерение в начале, аналог броадкастинга \n",
    "print(x.unsqueeze(0).squeeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.unsqueeze(0).squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы также можем переводить матрицы назад в numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1: \n",
    "\n",
    "- При помощи numpy посчитайте сумму квадратов чисел от 1 до 10000\n",
    "- Сделайте то же самое с помощью pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.square(np.arange(1, 10_000+1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .item() возвращает число из тензора. \n",
    "# Без этого будет тензор размерности 1x1\n",
    "\n",
    "torch.square(torch.arange(1, 10_000+1)).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ващ код  ¯\\_(⊙︿⊙)_/¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2:\n",
    "\n",
    "Реализуйте на PyTorch сигмоиду \n",
    "\n",
    "$$ \\sigma(x) = \\frac{1}{1 + e^{-x}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ващ код  ¯\\_(⊙︿⊙)_/¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3:\n",
    "\n",
    "Реализуйте на PyTorch среднюю квадратичную ошибку. \n",
    "\n",
    "$$ \n",
    "MSE(\\hat y, y) = \\frac{1}{n} \\cdot \\sum_{i=1}^n (\\hat y - y)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ващ код  ¯\\_(⊙︿⊙)_/¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_predict):\n",
    "    return torch.mean((y_true - y_pred)**2)\n",
    "\n",
    "z = mse(y_test, y_pred)\n",
    "z.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4:\n",
    "\n",
    "Что будет в переменной `x` в результате выполнения следующего кода? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "y = x\n",
    "y[2] = torch.ones(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как это можно исправить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ващ код  ¯\\_(⊙︿⊙)_/¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Производные да градиенты\n",
    "\n",
    "Если в PyTorch те же самые операции, что и в numpy, то на кой чёрт он нам нужен? В отличие от numpy, в PyTorch есть возможность при создании тензора указывать нужно ли считать по нему градиент или нет, с помощью параметра `requires_grad`. \n",
    "\n",
    "Когда `requires_grad=True` мы сообщаем фреймворку, о том, что мы хотим следить за всеми тензорами, которые получаются из созданного. Иными словами, у любого тензора, у которого указан данный параметр, будет доступ к цепочке операций и преобразований совершенными с ними. Если эти функции дифференцируемые, то у тензора появляется параметр `.grad`, в котором хранится значение градиента.\n",
    "\n",
    "Он проходит по всем операциям, которые фигурируют в графе вычислений, и применяет к ним chain rule:\n",
    "\n",
    "$$ {\\partial f(g(x)) \\over \\partial x} = {\\partial f(g(x)) \\over \\partial g(x)}\\cdot {\\partial g(x) \\over \\partial x} $$\n",
    "\n",
    "Давайте попробуем!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(\n",
    "    [0.3, 1], requires_grad=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.sum(x)\n",
    "z = y ** 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если к результирующему тензору применить метод `.backward()`, то фреймворк посчитает по цепочке градиенты для всех тензоров, у которых `requires_grad=True.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пока градиента нет\n",
    "print(x.grad, '<- gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward() # считаем градиент\n",
    "print(x.grad, '<- gradient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно:** если вы вычисляете градиент дважды, градиенты будут суммироваться в тензорах, поэтому полезно обнулять градиенты между итерациями.\n",
    "\n",
    "Обычно мы обучаем модель не по одному объекту, а на большой выборке. Вся выборка обычно в память не влезает. Мы прогоняем через нейросеть данные батчами. PyTorch позволяет накапливать градиенты по батчам не помещая в память все данные. Иногда это оказывается полезным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно посмотреть на порядок действий\n",
    "print(z.grad_fn)\n",
    "print(z.grad_fn.next_functions[0][0])\n",
    "print(z.grad_fn.next_functions[0][0].next_functions[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5:\n",
    "\n",
    "Реализуйте расчёт градиента для функции \n",
    "\n",
    "$$\n",
    "f(w) = \\prod_{i,j} \\ln(\\ln(w_{ij} + 7) \n",
    "$$\n",
    "\n",
    "в точке `w = [[5,10], [1,2]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ващ код  ¯\\_(⊙︿⊙)_/¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Оптимизация\n",
    "\n",
    "Итак, PyTorch умеет искать производные, осталось научиться применять его для оптимизации. \n",
    "\n",
    "Давайте обучим линейную регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "plt.scatter(data[:, -1], target);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам надо обучить линейную регрессию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(data[:, -1] / data[:, -1].max(), dtype=torch.float32)\n",
    "y = torch.tensor(target, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наша модель\n",
    "def linear_regression(x):\n",
    "    return w*x + b\n",
    "\n",
    "# Ошибка для модели\n",
    "def mean_square(y_pred, y_true):\n",
    "    return torch.mean((y_pred-y_true)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = linear_regression(x)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = mean_square(pred, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем градиенты\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dL/dw = \\n\", w.grad)\n",
    "print(\"dL/db = \\n\", b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим нашу линейную регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "epochs = 1000 # число эпох \n",
    "\n",
    "w = torch.randn(1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    y_pred = w * x + b\n",
    "    loss = torch.mean((y_pred - y)**2)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "\n",
    "    # делаем шаг градиентного спуска с lr = .05\n",
    "    w.data -= 0.05 * w.grad.data \n",
    "    b.data -= 0.05 * b.grad.data\n",
    "\n",
    "    # обнуляем градиенты, чтобы на следующем шаге опять посчитать и не аккумулировать их\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "    # рисуем картинки\n",
    "    if (i+1) % 5 == 0:\n",
    "        clear_output(True)\n",
    "        plt.scatter(x.data.numpy(), y.data.numpy())\n",
    "        plt.scatter(x.data.numpy(), y_pred.data.numpy(),\n",
    "                    color='orange', linewidth=5)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"loss = \", loss.data.numpy())\n",
    "        if loss.data.numpy() < 0.5:\n",
    "            print(\"Done!\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6:\n",
    "\n",
    "Реализуйте для функции \n",
    "\n",
    "$$\n",
    "f(w) = \\prod_{i,j} \\ln(\\ln(w_{ij} + 7) \n",
    "$$\n",
    "\n",
    "процедуру градиентного спуска. Каким получилось минимальное значение? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ващ код  ¯\\_(⊙︿⊙)_/¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Моя первая нейросеть \n",
    "\n",
    "Для того, чтобы разобраться как обучать нейросетки, нужно освоить три вещи: \n",
    "\n",
    "1. Как обрабатывать поток данных и пихать его в сетку\n",
    "2. Как сделать сетку\n",
    "3. Как написать цикл обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Как формировать батчи и пихать их в сетку\n",
    "\n",
    "С данными помогают работать две абстракции: `Dataset` и `DataLoader`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset` умеет выдавать по индексу некоторый элемент и помогает итерироваться по данным. Чтобы работать с данными и применять к ним преобразования, например, аугментации, о которых вы узнаете позже — нужно создать свой класс унаследованный от `torch.utils.data.Dataset`.\n",
    "\n",
    "Вот пример из документации:\n",
    "\n",
    "```\n",
    "class FaceLandmarksDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "```\n",
    "\n",
    "Как вы видите, у такого класса должно быть два метода: \n",
    "\n",
    "* `__len__` — возвращает информацию о том, сколько объектов у нас в датасете\n",
    "* `__getitem__` — возвращает семпл и таргет к нему\n",
    "\n",
    "Теперь давайте напишем такой сами, в качестве датасета сгенерируем рандомные данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Our random dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {'sample': torch.tensor(x[idx, :], dtype=torch.float), 'target': y[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(1000, 5)\n",
    "y = np.random.rand(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_dataset = RandomDataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset` умеет говорить сколько в выборке объектов и брать из неё очередной. Этого мало. Данные хочется как-то видоизменять. Для этого есть такая сущность как `DataLoader`.\n",
    "\n",
    "Он принимает на вход класс унаследованный от `torch.utils.data.Dataset` и преобразовывает его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(our_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работают с ним следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    batch_x = batch['sample']\n",
    "    batch_y = batch['target']\n",
    "    break\n",
    "    \n",
    "print('Sample:', batch_x)\n",
    "print('Target:', batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Нейронная сеть\n",
    "\n",
    "Есть несколько способов собрать нейросетку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Способ 1:__ Для того, чтобы в high-level pytorch создавать нейросети используется модуль `nn`. Нейросеть должна быть унаследована от класса `nn.Module`. Пример как это может выглядеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(5, 3)\n",
    "        self.layer2 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        return F.relu(self.layer2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим на данном примере, у данного класса должно быть метод `forward`, который определяет прямой проход нейросети. Также из класса выше видно, что модуль `nn` содержит в себе реализацию большинства слоев, а модуль `nn.functional`—  функций активаций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model(batch_x) # получили предсказания модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы не очень поняли, что произошло, не пугайтесь. На следующих семинарах мы более подробно будем говорить про объектно-ориентированное программирование и научимся писать подобные модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Способ 2:__ Можно собрать модель с помощью класса `Sequential`. В его рамках сбор модели будет выглядить как строительство башни из конструктора LEGO. Модель описывается последовательно. Мы как бы создаём коробочку `model` и постепенно добавляем туда детальки нашей сетки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()                 # создаем пустую модель, в которую будем добавлять слои\n",
    "model.add_module('l1', nn.Linear(5, 3)) # добавили слой с 5-ю нейронами на вход и 3-мя на выход\n",
    "model.add_module('l2', nn.ReLU())       # добавили функцию активации\n",
    "model.add_module('l3', nn.Linear(3, 1)) # добавили слой с 3-мя нейронами на вход и 5-ю на выход"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(batch_x) # получили предсказания модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Способ 3:__ Описать модель функционально, в явном виде прописав какие аргументы идут на вход какому слою. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = nn.Linear(5, 3)(batch_x)\n",
    "h = nn.ReLU()(h)\n",
    "out = nn.Linear(3, 1)(h)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно модель объявляют в виде класса, а второй и третий способ используют, чтобы вычисления внутри него выглядели более красиво."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Цикл для обучения модели\n",
    "\n",
    "Осталось научиться писать циклы для обучения. Давайте подгрузим настоящие данные, соберём модель и обучим её."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# внутри модуля transforms есть много полезных преобразований\n",
    "# пока что нам из него понадобится только T.ToTensor() \n",
    "# для конвертации картинки в тензор \n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не будем выпендриваться и как все обучим [наборе рукопистных цифр MNIST.](http://yann.lecun.com/exdb/mnist/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MNIST('.MNIST', transform=T.ToTensor(), train=True, download=True)\n",
    "test_set = MNIST('.MNIST', transform=T.ToTensor(), train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_set` в данном случае это датасет. Давайте нарисуем несколько изображений. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 8\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(2 * cols, 2.5 * rows))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, len(train_set))\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(train_set[random_index][0].squeeze(0).numpy().reshape([28, 28]), cmap = 'gray')\n",
    "        ax.set_xlabel(train_set[random_index][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая картинка это матрица из чисел. Если число большое - пиксель яркий. Если маленькое - тёмный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[5][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем прогнозировать тип картинки по её пикселям. Подготовим данные с помощью `DataLoader`. Пока что попробуем настроить его максимально просто. В будущем мы увидим с вами другую магию, на которую способна эта абстракция. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7:\n",
    "\n",
    "Напишите `DataLoader` для тренировочной и тестовой выборок. Попробуйте проитерироваться по нескольким его первым объектам с помощью цикла.\n",
    "\n",
    "В обучающей выборке данные должны перемешиваться каждую эпоху. Размер батча поставьте равным 64. В тестовой выборке данных перемешивать не надо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ващ код  ¯\\_(⊙︿⊙)_/¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 8:\n",
    "\n",
    "Напишите  двухслойную полносвязную нейросеть. Выходной слой должен состоять из $10$ нейронов с `Softmax` в качестве функции активации, так как мы решаем задачу классификации $10$ классов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, num_classes, hidden_size):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            \n",
    "            # ващ код  ¯\\_(⊙︿⊙)_/¯\n",
    "            # ващ код  ¯\\_(⊙︿⊙)_/¯\n",
    "            # ващ код  ¯\\_(⊙︿⊙)_/¯\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(28**2, 10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса моделей хранятся в виде матриц и выглядят так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x for x in model.named_parameters()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявляем модель и оптимизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 28\n",
    "NUM_CLASSES = 10\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = MLP(in_features=IMG_SIZE ** 2, num_classes=NUM_CLASSES, hidden_size=HIDDEN_SIZE).to(device)\n",
    "\n",
    "# оптимайзер\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# функция потерь \n",
    "criterion = nn.CrossEntropyLoss()  # nn.NLLLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось всё это дело обучить. Для этого нам придётся написать цикл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# NUM_EPOCHS раз подряд пройдемся по всем батчам из трейна\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    # берем батч из трейн лоадера\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        \n",
    "        # отправляем тензоры на девайс к сетке\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        ### Пишем самые важные 5 строк\n",
    "        ### Мы их дальше будем встречать везде\n",
    "        \n",
    "        # зануляем старые градиенты иначе они сложатся\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # вызываем модель\n",
    "        logits = model(torch.flatten(images, start_dim=1))\n",
    "        # (batch_size, x, num_classes) - размерность\n",
    "        \n",
    "        # считаем функцию потерь \n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # считаем градиенты обратным проходом\n",
    "        loss.backward() \n",
    "        \n",
    "        # обновляем параметры сети (шаг спуска)\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 2 == 0:\n",
    "        mean_val_loss = [] # сюда будем складывать средний лосс по батчам\n",
    "        val_accuracy = []\n",
    "        \n",
    "        # берем батч из вал лоадера для валидации\n",
    "        for images, labels in tqdm(test_loader, desc='Validating'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # мы считаем качество, поэтому мы запрещаем фреймворку считать градиенты по параметрам\n",
    "            with torch.no_grad(): \n",
    "                # делаем предсказания\n",
    "                logits = model(torch.flatten(images, start_dim=1))\n",
    "                \n",
    "                # считаем ошибку на валидации\n",
    "                loss = criterion(logits, labels)\n",
    "                \n",
    "                mean_val_loss.append(loss.numpy()) # добавляем в массив \n",
    "                val_accuracy.extend((torch.argmax(logits, dim=-1) == labels).numpy().tolist())\n",
    "        \n",
    "        # выводим статистику\n",
    "        print('Epoch: {epoch}, loss: {loss}, accuracy: {accuracy}'.format(\n",
    "                epoch=epoch, loss=np.mean(mean_val_loss), accuracy=np.mean(val_accuracy)\n",
    "        )) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, что всё работает. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ещё одно задание:\n",
    "\n",
    "На следующей паре мы продолжим обучать эту сетку и попробуем улучшить получившийся у нас пайплайн. Попробуйте для удобства вынести один шаг обучения модели и один шаг валидации модели в отдельные небольшие функции, чтобы код стал более читаемым. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Почиташки\n",
    "\n",
    "__Откуда взялась эта тетрадка?__ \n",
    "\n",
    "Когда я писал эту тетрадку, я ориентировался на четыре источника:\n",
    "\n",
    "- [Введение в pytorch от ШАД](https://github.com/yandexdataschool/Practical_DL/blob/fall22/week02_autodiff/seminar_pytorch.ipynb)\n",
    "- [Тетрадка с введением в pytorch с ИАД](https://github.com/hse-ds/iad-deep-learning/blob/master/2022/seminars/sem01/sem01.ipynb) (её взяли из ШАД)\n",
    "- [Введение в pytorch от Samsung](https://github.com/SlinkoIgor/Neural_Networks_and_CV)\n",
    "- [Экспромт Ильдуса с семинаров по DL на ФКН](https://github.com/isadrtdinov/intro-to-dl-hse/tree/2022-2023/seminars/202)\n",
    "\n",
    "Я добавил к ним свою больную фантазию и получилось то, что получилось.\n",
    "\n",
    "\n",
    "__Что можно почитать?__\n",
    "\n",
    "* [Документация торча](https://pytorch.org/docs/master/)\n",
    "* [Использование pytorch на GPU](https://pytorch.org/docs/master/notes/cuda.html)\n",
    "* [Хорошая книга про pytorch](http://download.webclark.org/Deep-Learning-with-PyTorch.pdf)\n",
    "* [Pytorch за 60 минут](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "* [Как устроено автоматическое дифференцирование в pytorch](http://videolectures.net/site/normal_dl/tag=1129745/deeplearning2017_johnson_automatic_differentiation_01.pdf)\n",
    "* [PyTorch examples](https://github.com/pytorch/examples)\n",
    "* [Practical pytorch tutorials](https://github.com/spro/practical-pytorch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
