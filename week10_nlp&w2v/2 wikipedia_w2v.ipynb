{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как научить компьютер читать?\n",
    "\n",
    "В этой тетрадке мы обучим свой w2v на википедии, а ещё возьмём чужой. Будем сравнивать эти две модели между собой.\n",
    "\n",
    "word2vec был разработан группой исследователей Google в 2013 году, руководителем проекта был Томаш Миколов (сейчас работает в Facebook). Вот две самые главные статьи:\n",
    "\n",
    "* [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "* [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка и обучение\n",
    "\n",
    "Будем обучать w2v модель на википедии. К счастью, в её случае для всех языков предусмотрена система дампов. С [удобной странчки](https://dumps.wikimedia.org) можно скачать текущую полную версию википедийного текста на любом языке. Например, [на русском.](https://dumps.wikimedia.org/ruwiki/).\n",
    "\n",
    "Для обучения модели будем использовать библиотеку `gensim`. В ней уже есть удобный модуль доя работы с википедийными дампами, а также готовая хорошая реализация w2v-сетки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# на моём копуктере дамп википедии лежал вот тут:\n",
    "path = \"/Users/fulyankin/Yandex.Disk.localized/Научные проекты/w2v/ruwiki-20180320-pages-articles-multistream.xml.bz2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы с текстами мы будем пользоваться библиотекой `gensim`. Она настолько хороша, что в ней есть даже специальные функции по работе с дампами с Википедии. Например, мы будем пользоваться для оценки модели специальным генератором, который будет считывать тексты с жёсткого диска по мере необходимости и не будет захламлять нам память. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.wikicorpus import WikiCorpus\n",
    "\n",
    "# для доступа к текстам мы будем пользоваться генератором wiki.get_texts()\n",
    "wiki = WikiCorpus(path, dictionary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корпус википедии, оказавшийся в наших руках уже прошёл очистку от мусора и был токенезирован. Про то, как обычно тексты чистят и предобрабатывают можно почитать [вот тут.](https://github.com/DmitrySerg/OpenData/blob/master/RussianElections2018/Part_2_data_preparation.ipynb) Посмотрим на первые $40$ слов самой первой её статьи. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['литва', 'официальное', 'название', 'лито', 'вская', 'респу', 'блика', 'государство', 'расположенное', 'северной', 'европе', 'одна', 'из', 'стран', 'балтии', 'столица', 'страны', 'вильнюс', 'площадь', 'км²', 'протяжённость', 'севера', 'на', 'юг', 'км', 'запада', 'на', 'восток', 'км', 'население', 'составляет', 'человек', 'по', 'этим', 'показателям', 'является', 'крупнейшим', 'прибалтийским', 'государством', 'имеет']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for text in wiki.get_texts( ):\n",
    "    i+=1\n",
    "    if i == 2:\n",
    "        break\n",
    "    else:\n",
    "        print(text[:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что многие слова оказались битыми. Например, слово \"литовская\" развалилось на \"лито\" и \"вская\". Предобработка была сделана не очень аккуратно. Тем не менее, у нас очень большой корпус документов. Закон больших чисел разрешает проигнорировать такие косяки. \n",
    "\n",
    "Попробуем выделить в тексте основные биграммы. Будем рассматривать их в дальнейшем как цельные токены. Существует целый ряд алгоритмов, занимающихся этим. Обычно все они сводятся к поиску вероятностей совместного появления двух слов в тексте. \n",
    "\n",
    "Код ниже, для большого корпуса текстов, будет работать довольно долго, но зато на выходе мы получим словарь биграмм, который мы сможем впоследствии применять к потоку текстов командой `bigram_transformer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34min 40s, sys: 1min 32s, total: 36min 13s\n",
      "Wall time: 44min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# хочется посмотреть на самые частые биграммы и использовать их при обучении как токены\n",
    "bigram = Phrases(wiki.get_texts())\n",
    "bigram_transformer = Phraser(bigram)\n",
    "\n",
    "# генератор текстов с биграммами\n",
    "def text_generator_bigram( ):\n",
    "    for text in wiki.get_texts( ):\n",
    "        yield bigram_transformer[[word for word in text]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим что нам будет выдавать такой генератор на примере первой статьи с википедии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['литва', 'официальное', 'название', 'лито_вская', 'респу_блика', 'государство', 'расположенное', 'северной', 'европе', 'одна', 'из', 'стран_балтии', 'столица', 'страны', 'вильнюс', 'площадь_км²', 'протяжённость', 'севера', 'на', 'юг']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for item in text_generator_bigram( ):\n",
    "    i +=1 \n",
    "    if i == 2:\n",
    "        break\n",
    "    else:\n",
    "        print(item[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошая новость: мы поправили некоторые косяки предобработки и скрепили слово \"литовская\" в единое целое. Другой вопрос в том, что у нас в корпусе теперь есть слово \"лито_вская\" и \"литовская\". Алгоритм будет думать, что это разные слова. Интересно будет в конце посмотреть насколько близки будут их вектора. \n",
    "\n",
    "Кроме всего прочьего, у нас в выборке появились и настояшие биграммы. Например, \"площадь_км²\". По аналогии можно соорудить код для поиска самых частых триграмм. Например, триграммой будет словосочетание \"по моему мнению\" или \"вторая мировая война\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 7min 39s, sys: 2min 25s, total: 1h 10min 4s\n",
      "Wall time: 2h 10min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trigram = Phrases(text_generator_bigram())\n",
    "trigram_transformer = Phraser(trigram)\n",
    "\n",
    "def text_generator_trigram():\n",
    "    for text in wiki.get_texts():\n",
    "        yield trigram_transformer[bigram_transformer[[word for word in text]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['литва', 'официальное_название', 'лито_вская', 'респу_блика_государство', 'расположенное', 'северной', 'европе', 'одна', 'из', 'стран_балтии', 'столица', 'страны', 'вильнюс', 'площадь_км²', 'протяжённость_севера', 'на', 'юг', 'км', 'запада', 'на']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for item in text_generator_trigram( ):\n",
    "    i +=1 \n",
    "    if i == 2:\n",
    "        break\n",
    "    else:\n",
    "        print(item[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом давайте закончим нашу подготовку и попробуем собрать и обучить модель. Конечно же учиться она будет довольно долго. Не факт, что на слабом компьютере она вообще выучится. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 7min 3s, sys: 1min 57s, total: 1h 9min\n",
      "Wall time: 1h 14min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "# теперь сама модель\n",
    "# size - размерность векторов, которые мы хотим обучить\n",
    "# window - ширина окна контекста\n",
    "# min_count - если слово встречается реже, для него не учим модель\n",
    "model = Word2Vec(size=300, window=7, min_count=10, workers=4)\n",
    "\n",
    "# строительство словаря, чтобы обучение шло быстрее\n",
    "model.build_vocab(text_generator_trigram())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 43min 22s, sys: 5min 24s, total: 1h 48min 47s\n",
      "Wall time: 1h 25min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "323437961"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# обучение модели \n",
    "# первый аргумент - наша выборка, генератор будет вкидывать в модель наши тексты, пока они не кончатся\n",
    "# второй аргумент - число примеров в выборке \n",
    "# третий аргумент - количество эпох обучения: сколько раз модель пройдётся по всему корпусу текстов\n",
    "\n",
    "model.train(text_generator_trigram(), total_examples=model.corpus_count, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обученную модель можно сохранить. Процесс её обучения довольно трудоёмок, не очень хочется его повторять по несколько раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним обученную модель\n",
    "model.save('wiki_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По аналогии можно сохранить создатель триграмм. Он тоже учился довольно долго, а нам хотелось бы в дальнейшем его переиспользовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigram_transformer.save('wiki_trigramm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Изучаем свойства модели\n",
    "\n",
    "Итак, самая сложная часть оказалась позади. Модель обучено. Теперь пришло время немного поисследовать свойства, которыми модель обладает. Попробуем посмотреть на линейные соотношения между векторами, соотвествующими тем или иным слова в получившемся семантическом пространстве. \n",
    "\n",
    "Скачаем одну из моделей с проекта [rusvectores](https://rusvectores.org/ru/models/) и сравним с ней свойства нашей модели. Возьмём модель с гордым именем `ruwikiruscorpora_upos_skipgram_300_2_2018`, обученую на корпусе Википедии и НКРЯ (национальный корпус русского языка) в декабре 2017 года. \n",
    "\n",
    "W2V модели учат для самых различных целей. Какие-то из корпусов лемматизируют, какие нет. Мы, обучая модель на википедии, не делали лемматизацию. В случае rusvec-модели лемматизация была сделана. Более того, их модель училась на больших объёмах данных, чем наша. Также в ней выделены различные части речи, присущие словам. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели word2vec бывают разных форматов:\n",
    "\n",
    "* `.vec.gz` — обычный файл\n",
    "* `.bin.gz` — бинарник\n",
    "\n",
    "Загружаются они с помощью одного и того же класса `KeyedVectors`, меняется только параметр `binary` у функции `load_word2vec_format`. \n",
    "\n",
    "Если же эмбеддинги обучены **не** с помощью word2vec, то для загрузки нужно использовать функцию `load`. Т.е. для загрузки предобученных эмбеддингов *glove, fasttext, bpe* и любых других нужна именно она."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# подгрузим обученную модель, если вдруг мы сбросили скрипт\n",
    "our_model = gensim.models.Word2Vec.load('models/wiki_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подгрузим модель, обученную ребятами из rusvectores \n",
    "rv_name = 'models/ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz'\n",
    "rusvec_model = gensim.models.KeyedVectors.load_word2vec_format(rv_name,\n",
    "                                                    binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала посмотрим как выглядит слово в получившемся пространстве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4187494 ,  1.3197291 ,  0.5561069 , -2.674209  , -0.39070314,\n",
       "       -1.7381759 ,  2.4423337 ,  1.1509248 ,  0.49805412,  1.0481958 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вектор слова\n",
    "our_model.wv['король'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помотрим на размерность вектора в рамках нашей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.wv['король'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на размерность вектора в рамках rusvec модели. При оценивании своих моделей ребята пытаются уточнять в разметке части речи для всех слов с помощью своих разметок и специальных алгоритмов. Если вам вдруг захотелось тоже протэгировать частьми речи слова, `pymorty2` и `pymystem` умеют это делать. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusvec_model.wv['король_NOUN'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Похожесть слов\n",
    "\n",
    "Можно посмотреть насколько различные слова похожи между собой в семантическом плане. Похожесть между словами считается с помощью косинусной метрики. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "грязный и вонючий: 0.7032279588356054\n",
      "грязный и убранный: 0.6671076378477605\n",
      "грязный и грязный: 1.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "# наша модель\n",
    "print('грязный и вонючий:', our_model.wv.similarity('грязный', 'вонючий'))\n",
    "print('грязный и чистый:', our_model.wv.similarity('грязный', 'чистый'))\n",
    "print('грязный и грязный:', our_model.wv.similarity('грязный', 'грязный'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "грязный и вонючий: 0.6302576004741985\n",
      "грязный и убранный: 0.3905526637350729\n",
      "грязный и грязный: 1.0\n"
     ]
    }
   ],
   "source": [
    "# rusvec модель\n",
    "print('грязный и вонючий:', rusvec_model.wv.similarity('грязный_ADJ', 'вонючий_ADJ'))\n",
    "print('грязный и чистый:', rusvec_model.wv.similarity('грязный_ADJ', 'чистый_ADV'))\n",
    "print('грязный и грязный:', rusvec_model.wv.similarity('грязный_ADJ', 'грязный_ADJ'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Самые близкие слова\n",
    "\n",
    "Можно посмотреть на самые близкие слова к какому-то конкретному слову. Посмотрим на самые близкие слова к слову грязный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('шумный', 0.824225902557373),\n",
       " ('грустный', 0.8109831213951111),\n",
       " ('жуткий', 0.8098311424255371),\n",
       " ('ужасный', 0.8051483631134033),\n",
       " ('тёмный', 0.7896004915237427),\n",
       " ('темный', 0.7869464755058289),\n",
       " ('нежный', 0.7816108465194702),\n",
       " ('жирный', 0.7760384678840637),\n",
       " ('весёлый', 0.774817705154419),\n",
       " ('громкий', 0.7737864255905151)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.most_similar('грязный')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('грязноватый_ADJ', 0.660734236240387),\n",
       " ('грязнейший_ADJ', 0.6599724292755127),\n",
       " ('неопрятный_ADJ', 0.634252667427063),\n",
       " ('вонючий_ADJ', 0.6302576065063477),\n",
       " ('запачкать_VERB', 0.61855149269104),\n",
       " ('заплеванный_VERB', 0.6133441925048828),\n",
       " ('запачканный_VERB', 0.6034902334213257),\n",
       " ('испачкать_ADJ', 0.5984973907470703),\n",
       " ('загаженный_VERB', 0.5979785919189453),\n",
       " ('мерзкий_ADJ', 0.5978673696517944)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusvec_model.most_similar('грязный_ADJ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что чужая модель выгодно отличается от нашей. Посмотрим ещё на пару примеров. Нас интересует дружелюбие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('неуклюжий', 0.8484416007995605),\n",
       " ('добродушный', 0.846727728843689),\n",
       " ('эгоистичный', 0.8443366289138794),\n",
       " ('обаятельный', 0.8425811529159546),\n",
       " ('вспыльчивый', 0.8413093686103821),\n",
       " ('самоуверенный', 0.8410248756408691),\n",
       " ('жизнерадостный', 0.8406734466552734),\n",
       " ('застенчивый', 0.8355358839035034),\n",
       " ('вежливый', 0.8343687653541565),\n",
       " ('наивный', 0.8318225145339966)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.most_similar('дружелюбный')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('доброжелательный_ADJ', 0.7317343354225159),\n",
       " ('добродушный_ADJ', 0.6525911092758179),\n",
       " ('приветливый_ADJ', 0.6513131856918335),\n",
       " ('уживчивый_ADJ', 0.6482845544815063),\n",
       " ('коммуникабельный_ADJ', 0.6472278833389282),\n",
       " ('общительный_ADJ', 0.6395638585090637),\n",
       " ('неконфликтный_ADJ', 0.6390734910964966),\n",
       " ('доброжелательной_ADJ', 0.632719874382019),\n",
       " ('приветливый_NOUN', 0.6252726316452026),\n",
       " ('миролюбивый_ADJ', 0.6205745935440063)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusvec_model.most_similar('дружелюбный_ADJ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нас интересует Шок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('бред', 0.7624124884605408),\n",
       " ('психоз', 0.7540462017059326),\n",
       " ('стресс', 0.7503001689910889),\n",
       " ('страх', 0.7487086057662964),\n",
       " ('головокружение', 0.7479767799377441),\n",
       " ('обморок', 0.7372667193412781),\n",
       " ('ступор', 0.7199352979660034),\n",
       " ('боли', 0.716423511505127),\n",
       " ('раздражение', 0.7102159857749939),\n",
       " ('оргазм', 0.7092399001121521)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.most_similar('шок')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('шоко_NOUN', 0.6282049417495728),\n",
       " ('гиповолемический_ADJ', 0.6145074963569641),\n",
       " ('шоковой_ADJ', 0.6083506345748901),\n",
       " ('кардиогенный_ADJ', 0.5890294313430786),\n",
       " ('обморок_NOUN', 0.5806757807731628),\n",
       " ('коматозный_ADJ', 0.5661958456039429),\n",
       " ('анафилактический_ADJ', 0.556747555732727),\n",
       " ('инсульта_NOUN', 0.5564901232719421),\n",
       " ('стресс_NOUN', 0.5562987923622131),\n",
       " ('анафилактоидный_ADJ', 0.5518753528594971)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusvec_model.most_similar('шок_NOUN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во многих вещах наши модели согласны друг с другом. Движемся дальше! Настал черёд арифметики.\n",
    "\n",
    "### 2.3 Арифметика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем провернуть первое уравнение. \n",
    "\n",
    "$$ Король + Женшина - Мужчина = \\quad ???$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('королева', 0.6225535869598389),\n",
       " ('империя', 0.5604485869407654),\n",
       " ('принцесса', 0.5506317615509033),\n",
       " ('императрица', 0.5310197472572327),\n",
       " ('король_ок_ок', 0.5229284763336182)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.most_similar(positive=['женщина', 'король'], negative=['мужчина'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('королева_NOUN', 0.7153134346008301),\n",
       " ('королева_ADV', 0.6489790678024292),\n",
       " ('король_PROPN', 0.5975136756896973),\n",
       " ('королева_ADJ', 0.5909769535064697),\n",
       " ('короля_NOUN', 0.5825802087783813)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusvec_model.most_similar(positive=['женщина_NOUN', 'король_NOUN'], \n",
    "                             negative=['мужчина_NOUN'])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Москва + Франция - Россия = \\quad ???$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('париж', 0.5632048845291138),\n",
       " ('жан', 0.5306471586227417),\n",
       " ('жак', 0.5089118480682373),\n",
       " ('пьер', 0.5062865018844604),\n",
       " ('французский', 0.5051255822181702)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.most_similar(positive=['москва', 'франция'], negative=['россия'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('париж_NOUN', 0.4464000165462494),\n",
       " ('италия_NOUN', 0.4293068051338196),\n",
       " ('брюссель_NOUN', 0.4278932809829712),\n",
       " ('швеция_NOUN', 0.4128666818141937),\n",
       " ('англия_NOUN', 0.40511107444763184)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusvec_model.most_similar(positive=['москва_NOUN', 'франция_NOUN'], negative=['россия_NOUN'])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Математик + Женшина - Мужчина = \\quad ???$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('филолог', 0.6791591048240662),\n",
       " ('получившая_степень_доктора', 0.665369987487793),\n",
       " ('лингвист', 0.6601260900497437),\n",
       " ('доктор_философии', 0.6564381122589111),\n",
       " ('доктор_филологических_наук', 0.6553531885147095)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.most_similar(positive=['математик', 'женщина'], negative=['мужчина'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('физик_NOUN', 0.6517059803009033),\n",
       " ('физик-теоретик_NOUN', 0.6240127086639404),\n",
       " ('философ_NOUN', 0.6040728688240051),\n",
       " ('физико-химик_NOUN', 0.597895622253418),\n",
       " ('геометр_NOUN', 0.5913760662078857)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusvec_model.most_similar(positive=['математик_NOUN', 'женщина_NOUN'], negative=['мужчина_NOUN'])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему-то наша модель оказалась сексистом... Это артефакт выборки. Запомните про это, ниже мы обсудим артефакты подробнее. \n",
    "\n",
    "$$ Человек - Животное = \\quad ???$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('тысяч_человек', 0.4908541440963745),\n",
       " ('тыс_человек', 0.4347049593925476),\n",
       " ('райкомы', 0.38436031341552734),\n",
       " ('делегатов', 0.3816929757595062),\n",
       " ('штатных_сотрудников', 0.3813714385032654)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.most_similar(positive=['человек'],negative=['животное'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('чел[овек_NOUN', 0.3204188346862793),\n",
       " ('человек_PROPN', 0.299196720123291),\n",
       " ('человѣкъ_PROPN', 0.29532384872436523),\n",
       " ('человеколо_NOUN', 0.2849539816379547),\n",
       " ('человек_VERB', 0.28311628103256226)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusvec_model.most_similar(positive=['человек_NOUN'],negative=['животное_NOUN'])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении н английском корпусе слов, можно было бы уведить, что `Human - Animal = Ethics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('вице_президент', 0.5562783479690552),\n",
       " ('дмитрий_медведев', 0.5472823977470398),\n",
       " ('спикер', 0.5424843430519104),\n",
       " ('михаил_маргелов', 0.5396710634231567),\n",
       " ('вице_премьер', 0.5389058589935303)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.most_similar(positive=['президент'],negative=['мощь'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('президент_PROPN', 0.5648089647293091),\n",
       " ('вице-президент_NOUN', 0.5592658519744873),\n",
       " ('экс-президент_NOUN', 0.44517824053764343),\n",
       " ('экс-президентый_NOUN', 0.4248402714729309),\n",
       " ('премьер-министр_NOUN', 0.41906532645225525)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusvec_model.most_similar(positive=['президент_NOUN'],negative=['мощь_NOUN'])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И снова для русской википедии мы наблюдаем забавный артефакт :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('пиноккио', 0.8352062702178955),\n",
       " ('женщина_кошка', 0.8283794522285461),\n",
       " ('капитан_крюк', 0.8133963346481323),\n",
       " ('джинн', 0.8126029968261719),\n",
       " ('дракула', 0.809827446937561)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.most_similar(positive=['летучая_мышь','брюс_уэйн'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('листоносый_ADJ', 0.6629314422607422),\n",
       " ('мышью_NOUN', 0.6600611209869385),\n",
       " ('крыса_NOUN', 0.6554200649261475),\n",
       " ('micromys_PROPN', 0.641371488571167),\n",
       " ('мыши_NOUN', 0.6350268721580505)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusvec_model.most_similar(positive=['мышь_NOUN','летучий_ADJ','брюс_NOUN'])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению в выбранной мною для сравнения модели нет биграмм :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('гоблин', 0.8566164970397949),\n",
       " ('стервятник', 0.8511500358581543),\n",
       " ('росомаха', 0.850637674331665),\n",
       " ('веном', 0.8489575982093811),\n",
       " ('мутант', 0.845893383026123),\n",
       " ('циклоп', 0.8411886692047119),\n",
       " ('киборг', 0.8410425186157227),\n",
       " ('инопланетянин', 0.8373299241065979),\n",
       " ('злодей', 0.8354233503341675),\n",
       " ('пришелец', 0.8316423296928406)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.most_similar(positive=['питер_паркер','паук'])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('паук_PROPN', 0.6240770816802979),\n",
       " ('-паука_NOUN', 0.590177059173584),\n",
       " ('осьминог_PROPN', 0.5895593762397766),\n",
       " ('человек-паук_NOUN', 0.5872828960418701),\n",
       " ('гарри::озборн_PROPN', 0.584584653377533),\n",
       " ('питер_PROPN', 0.5779144167900085),\n",
       " ('-паук_NOUN', 0.5753026604652405),\n",
       " ('-паука_X', 0.5728250741958618),\n",
       " ('человек-паук_PROPN', 0.5703564882278442),\n",
       " ('хеллбой_NOUN', 0.5701111555099487)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusvec_model.most_similar(positive=['питер_NOUN','паук_NOUN'])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Ваши \\mbox{ } уравнения $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Идеи: \n",
    "# \n",
    "# пицца - италия + сибирь\n",
    "# любовь - секс \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Найди лишнее\n",
    "\n",
    "Можно попросить модель найти лишнее слово в каком-нибудь векторе. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'картофель_NOUN'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusvec_model.doesnt_match('яблоко_NOUN груша_NOUN виноград_NOUN банан_NOUN лимон_NOUN картофель_NOUN'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'яблоко'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.doesnt_match('яблоко груша виноград банан лимон картофель'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Взаимоотношения \n",
    "\n",
    "Если модель училась без лемматизации, можно попробовать увидеть не только то, что столицы взаимоотносятся с названиями стран одинаково, но и поймать более интересные эффекты.\n",
    "\n",
    "![w2v](https://cdn-images-1.medium.com/max/2600/1*sXNXYfAqfLUeiDXPCo130w.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'мадрид'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.most_similar(positive=['лондон', 'испания'], negative=['англия'])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, увидеть взаимотношения между единственным числои и множественным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'грузовики'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.most_similar(positive=['яблоки', 'грузовик'], \n",
    "                       negative=['яблоко'])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А также между разными степенями прилагательных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'страшный'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.most_similar(positive=['красивый', 'страшная'], \n",
    "                       negative=['красивая'])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно найти и многие другие интересные семантические свойства."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Артефакты\n",
    "\n",
    "Нужно понимать, что в выборке, на основе которой вы обучали модель могут быть различные \"артефакты\". Например, если мы обучались на корпусе новостей, мы можем неожиданно обнаружить, что к Индонезии очень близко землятрясение. Почему? Да просто потому что в корпусе все статьи, связанные с Индонезией упоминали недавнее землятрясение. С такми артефактами приходится бороться и переодически модель приходится переобучать. \n",
    "\n",
    "Одним из забавных артефактов, найденных в рамках нашей модели было то, что если отобрать у президнета мощь, получится Дмитрий Медведев. Вот другой пример подобного артефакта. Машина времени в контексте нашей модели это рок-группа. Никаких вещей, связанных с научной фантастикой не нарисовалось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('король_шут', 0.8701559901237488),\n",
       " ('агата_кристи', 0.8659921288490295),\n",
       " ('сплин', 0.8545758724212646),\n",
       " ('весёлые_ребята', 0.8407142162322998),\n",
       " ('чайф', 0.8382944464683533),\n",
       " ('ногу_свело', 0.8371785879135132),\n",
       " ('ночные_снайперы', 0.8325160145759583),\n",
       " ('наив', 0.8310174942016602),\n",
       " ('валерий_леонтьев', 0.8306418657302856),\n",
       " ('андрей_макаревич', 0.8283897638320923)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('машина_времени')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ссылки  да почиташки\n",
    "\n",
    "* [Про w2v и русский сексизм](https://nikolenko.livejournal.com/267442.html)\n",
    "* [Предобученная w2v для английского языка](https://code.google.com/archive/p/word2vec)\n",
    "* [Неплохая заметка со ссылками на 5 базовых работ по w2v](https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/)\n",
    "* [Rusvec-модели](https://rusvectores.org/ru/models/) и подробное описание проекта.\n",
    "* [Предобработчик текстов](https://github.com/akutuzov/webvectors/blob/master/preprocessing/rusvectores_tutorial.ipynb) для rusvec моделей. \n",
    "* [Статья про w2v для Хабра и преходов по ссылкам + обучение моделей на них](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_russian/tutorials/word2vec_demonzheg.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
